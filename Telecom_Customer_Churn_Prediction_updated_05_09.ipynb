{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8242ff3c",
   "metadata": {
    "id": "8242ff3c"
   },
   "source": [
    "**Import the required pacakges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4bdca6",
   "metadata": {
    "id": "3c4bdca6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(color_codes=True)             # To get diffent different colors\n",
    "pd.set_option('display.max_columns', None)  # To display the max columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fba6006",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "0fba6006",
    "outputId": "a5b5e4e5-bf64-4dba-942e-143f4773c124"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# My data file and python files is in same location\n",
    "# So no need to provide full path\n",
    "df = pd.read_csv('telecom_customer_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedc792",
   "metadata": {
    "id": "8aedc792"
   },
   "source": [
    "# Data Preprocessing Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f6277",
   "metadata": {
    "id": "aa0f6277",
    "outputId": "6c8a5e62-88ff-470b-f625-b5365cfc4709"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae692a",
   "metadata": {
    "id": "4fae692a",
    "outputId": "e0f13438-85ca-43d9-ae70-2bea59ce1f50"
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "\n",
    "# No of rows are 7043\n",
    "# No of columns are 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb1c9e",
   "metadata": {
    "id": "accb1c9e"
   },
   "outputs": [],
   "source": [
    "# Customer_ID and Zip code are just a ID\n",
    "# so that we can drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151002ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "151002ab",
    "outputId": "966eac8a-578c-482f-fcd5-4ecf012bee48"
   },
   "outputs": [],
   "source": [
    "# Drop identifier column\n",
    "df.drop(columns = ['Customer ID', 'Zip Code'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0138c71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0138c71",
    "outputId": "15b0c5c9-42ae-47af-b967-35a28250fe6d"
   },
   "outputs": [],
   "source": [
    "#Check the number of unique value from all of the object datatype\n",
    "df.select_dtypes(include='object').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e3d14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc6e3d14",
    "outputId": "187acf2c-9765-464d-f73f-743ec9fc8e37"
   },
   "outputs": [],
   "source": [
    "# Drop city column because it have alot of unique value\n",
    "df.drop(columns = 'City',\n",
    "          inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ce483d",
   "metadata": {
    "id": "85ce483d"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cba032",
   "metadata": {
    "id": "70cba032",
    "outputId": "6e81e723-07b9-4705-9c7c-5fbffa352dc4"
   },
   "outputs": [],
   "source": [
    "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
    "len(cat_vars)\n",
    "\n",
    "# There are 21 cat columns are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b01bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "960b01bb",
    "outputId": "3aa4b85e-7d81-4156-c0f8-e2285fc831d9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the names of all columns with data type 'object' (categorical columns)\n",
    "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(cat_vars)\n",
    "num_rows = (num_cols + 2) // 3\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a countplot for the top 6 values of each categorical variable using Seaborn\n",
    "for i, var in enumerate(cat_vars):\n",
    "    top_values = df[var].value_counts().nlargest(6).index\n",
    "    filtered_df = df[df[var].isin(top_values)]\n",
    "    sns.countplot(x=var, data=filtered_df, ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "    axs[i].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axs):\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba0037",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "efba0037",
    "outputId": "79f63f72-ab11-4ab8-eef6-d9336f523997"
   },
   "outputs": [],
   "source": [
    "# Get the names of all columns with data type 'int' or 'float'\n",
    "num_vars = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(num_vars)\n",
    "num_rows = (num_cols + 2) // 3\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a box plot for each numerical variable using Seaborn\n",
    "for i, var in enumerate(num_vars):\n",
    "    sns.boxplot(x=df[var], ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axs):\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff403e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6cff403e",
    "outputId": "b51fa9ff-35d2-4f4b-854f-e764aa5a7e5e"
   },
   "outputs": [],
   "source": [
    "# Get the names of all columns with data type 'int'\n",
    "int_vars = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(int_vars)\n",
    "num_rows = (num_cols + 2) // 3  # To make sure there are enough rows for the subplots\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a box plot for each integer variable using Seaborn with hue='attrition'\n",
    "for i, var in enumerate(int_vars):\n",
    "    sns.boxplot(y=var, x='Customer Status', data=df, ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axs):\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c953c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "54c953c1",
    "outputId": "abac2d17-e875-4fe7-8c71-b23b18bff13b"
   },
   "outputs": [],
   "source": [
    "# Get the names of all columns with data type 'int'\n",
    "int_vars = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(int_vars)\n",
    "num_rows = (num_cols + 2) // 3  # To make sure there are enough rows for the subplots\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a histogram for each integer variable\n",
    "for i, var in enumerate(int_vars):\n",
    "    df[var].plot.hist(ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axs):\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00d207",
   "metadata": {
    "id": "1d00d207"
   },
   "outputs": [],
   "source": [
    "# Customer_status:\n",
    "# Stayed\n",
    "# Joined\n",
    "# Churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bc82d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "858bc82d",
    "outputId": "5ac4e0af-9994-4fed-f058-e89227df4db2"
   },
   "outputs": [],
   "source": [
    "# Get the names of all columns with data type 'int'\n",
    "int_vars = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(int_vars)\n",
    "num_rows = (num_cols + 2) // 3  # To make sure there are enough rows for the subplots\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a histogram for each integer variable with hue='Attrition'\n",
    "for i, var in enumerate(int_vars):\n",
    "    sns.histplot(data=df, x=var,\n",
    "                 hue='Customer Status', kde=True, ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axs):\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae69e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fae69e5b",
    "outputId": "f9957734-239a-4868-b500-328f61df7ce5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the names of all columns with data type 'object' (categorical variables)\n",
    "cat_vars = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Exclude 'Attrition' from the list if it exists in cat_vars\n",
    "if 'Customer Status' in cat_vars:\n",
    "    cat_vars.remove('Customer Status')\n",
    "\n",
    "# Create a figure with subplots, but only include the required number of subplots\n",
    "num_cols = len(cat_vars)\n",
    "num_rows = (num_cols + 2) // 3  # To make sure there are enough rows for the subplots\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a count plot for the top 6 values of each categorical variable\n",
    "for i, var in enumerate(cat_vars):\n",
    "    top_values = df[var].value_counts().nlargest(6).index\n",
    "    filtered_df = df[df[var].isin(top_values)]\n",
    "    sns.countplot(x=var, hue='Customer Status', data=filtered_df, ax=axs[i])\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=90)\n",
    "\n",
    "# Remove any remaining blank subplots\n",
    "for i in range(num_cols, len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9402f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4c9402f4",
    "outputId": "f783caa9-bc6e-44ae-9ebc-289e58192249",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Get the names of all columns with data type 'object' (categorical variables)\n",
    "cat_vars = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Exclude 'Attrition' from the list if it exists in cat_vars\n",
    "if 'Customer Status' in cat_vars:\n",
    "    cat_vars.remove('Customer Status')\n",
    "\n",
    "# Create a figure with subplots, but only include the required number of subplots\n",
    "num_cols = len(cat_vars)\n",
    "num_rows = (num_cols + 2) // 3  # To make sure there are enough rows for the subplots\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 5*num_rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a count plot for the top 6 values of each categorical variable as a density plot\n",
    "for i, var in enumerate(cat_vars):\n",
    "    top_values = df[var].value_counts().nlargest(6).index\n",
    "    filtered_df = df[df[var].isin(top_values)]\n",
    "\n",
    "    # Set x-tick positions explicitly\n",
    "    tick_positions = range(len(top_values))\n",
    "    axs[i].set_xticks(tick_positions)\n",
    "    axs[i].set_xticklabels(top_values, rotation=90)  # Set x-tick labels\n",
    "\n",
    "    sns.histplot(x=var, hue='Customer Status', data=filtered_df, ax=axs[i], multiple=\"fill\", kde=False, element=\"bars\", fill=True, stat='density')\n",
    "    axs[i].set_xlabel(var)\n",
    "\n",
    "# Remove any remaining blank subplots\n",
    "for i in range(num_cols, len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf9475",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7baf9475",
    "outputId": "7eb4b4a1-2d4c-4baf-9bf0-9616b280bd99",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the maximum number of categories to show individually\n",
    "max_categories = 5\n",
    "\n",
    "# Filter categorical columns with 'object' data type\n",
    "cat_cols = [col for col in df.columns if col != 'y' and df[col].dtype == 'object']\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(cat_cols)\n",
    "num_rows = (num_cols + 2) // 3\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=3, figsize=(20, 5*num_rows))\n",
    "\n",
    "# Flatten the axs array for easier indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Create a pie chart for each categorical column\n",
    "for i, col in enumerate(cat_cols):\n",
    "    if i < len(axs):  # Ensure we don't exceed the number of subplots\n",
    "        # Count the number of occurrences for each category\n",
    "        cat_counts = df[col].value_counts()\n",
    "\n",
    "        # Group categories beyond the top max_categories as 'Other'\n",
    "        if len(cat_counts) > max_categories:\n",
    "            cat_counts_top = cat_counts[:max_categories]\n",
    "            cat_counts_other = pd.Series(cat_counts[max_categories:].sum(), index=['Other'])\n",
    "            cat_counts = cat_counts_top.append(cat_counts_other)\n",
    "\n",
    "        # Create a pie chart\n",
    "        axs[i].pie(cat_counts, labels=cat_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "        axs[i].set_title(f'{col} Distribution')\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axs):\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88105fd",
   "metadata": {
    "id": "d88105fd"
   },
   "source": [
    "# Data Preprocessing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c84042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0c84042",
    "outputId": "2db5f91d-999e-414c-e013-494ff6744edf"
   },
   "outputs": [],
   "source": [
    "# Check the amounnt of missing value\n",
    "check_missing = df.isnull().sum() * 100 / df.shape[0]\n",
    "check_missing[check_missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dad741",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4dad741",
    "outputId": "b7b7465d-199a-49b4-e66f-e4084be75fd3"
   },
   "outputs": [],
   "source": [
    "# Drop column with missing value more than 25%\n",
    "df.drop(columns = ['Churn Category', 'Churn Reason'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345cb707",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "345cb707",
    "outputId": "ac793221-e676-4d7a-d2c0-0bd239137bce"
   },
   "outputs": [],
   "source": [
    "# Check the amounnt of missing value\n",
    "check_missing = df.isnull().sum() * 100 / df.shape[0]\n",
    "check_missing[check_missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f71ec",
   "metadata": {
    "id": "477f71ec"
   },
   "outputs": [],
   "source": [
    "# Drop column with 21% missing value because they are in the same user that have missing value\n",
    "subset_columns = ['Internet Type', 'Avg Monthly GB Download',\n",
    "                  'Online Security', 'Online Backup',\n",
    "                  'Device Protection Plan', 'Premium Tech Support',\n",
    "                  'Streaming TV', 'Streaming Movies',\n",
    "                  'Streaming Music', 'Unlimited Data']\n",
    "df.dropna(subset=subset_columns, inplace=True)\n",
    "\n",
    "# I just drop the missing values\n",
    "# If you want to impute you can impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a2d82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c77a2d82",
    "outputId": "2631c6cf-c047-44bb-ec7b-00a736179de2"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f18ee4",
   "metadata": {
    "id": "c3f18ee4"
   },
   "outputs": [],
   "source": [
    "# Drop column with 9% missing value because they are in the same user that have missing value\n",
    "subset_columns = ['Avg Monthly Long Distance Charges',\n",
    "                  'Multiple Lines']\n",
    "df.dropna(subset=subset_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a14bb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54a14bb3",
    "outputId": "b64a9ae0-9464-461a-d19e-a9ac826e1467"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ed17a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7ed17a",
    "outputId": "a3b05b3c-586e-4ebb-84ed-92f051dd129b"
   },
   "outputs": [],
   "source": [
    "# Check again the amounnt of missing value\n",
    "check_missing = df.isnull().sum() * 100 / df.shape[0]\n",
    "check_missing[check_missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54190a72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54190a72",
    "outputId": "7fb4fc60-a4c4-41ed-bc09-d73228da45ee"
   },
   "outputs": [],
   "source": [
    "# Multi classification or Bi classifiacion\n",
    "df['Customer Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c5b5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d80c5b5c",
    "outputId": "adc9740b-906e-419d-8bbb-2a73d0f17494"
   },
   "outputs": [],
   "source": [
    "# Change Joined into stayed, so we can make binary classification\n",
    "# Replace all values in the 'Customer Status' column with 'Stayed'\n",
    "df['Customer Status'] = df['Customer Status'].replace('Joined', 'Stayed')\n",
    "df['Customer Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb79652",
   "metadata": {
    "id": "5cb79652"
   },
   "source": [
    "# Label Encoding for Object Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dc215",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b1dc215",
    "outputId": "b06c68df-62aa-477f-e06a-5e6ed2002f67",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over each column in the DataFrame where dtype is 'object'\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "\n",
    "    # Print the column name and the unique values\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f39797",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08f39797",
    "outputId": "e67ee8de-0e1f-41b9-cf1b-440a4fa4bc23"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Loop over each column in the DataFrame where dtype is 'object'\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "\n",
    "    # Initialize a LabelEncoder object\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "    # Fit the encoder to the unique values in the column\n",
    "    label_encoder.fit(df[col].unique())\n",
    "\n",
    "    # Transform the column using the encoder\n",
    "    df[col] = label_encoder.transform(df[col])\n",
    "\n",
    "    # Print the column name and the unique encoded values\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47f622",
   "metadata": {
    "id": "ff47f622"
   },
   "outputs": [],
   "source": [
    "#Customer Status: ['Stayed' 'Churned']\n",
    "#Customer Status: [1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9d6e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8ef9d6e9",
    "outputId": "7a9a646b-11f3-4a85-d6d3-65c128329038"
   },
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(40, 32))\n",
    "sns.heatmap(df.corr(), fmt='.2g', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a20e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "376a20e8",
    "outputId": "abb1a5e6-62de-4de2-8379-5a91df6be025"
   },
   "outputs": [],
   "source": [
    "# Remove Internet Service and Phone Service column because of zero correlation\n",
    "df.drop(columns = ['Internet Service', 'Phone Service'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3d25e",
   "metadata": {
    "id": "f6e3d25e"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696874c",
   "metadata": {
    "id": "8696874c"
   },
   "outputs": [],
   "source": [
    "# this is your job\n",
    "# eda ====== all numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c7542",
   "metadata": {
    "id": "b44c7542"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f041e",
   "metadata": {
    "id": "e27f041e"
   },
   "outputs": [],
   "source": [
    "# Target_columns= 'Customer Status'\n",
    "# Other than customer status all are input columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4b80f",
   "metadata": {
    "id": "c1e4b80f"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Customer Status', axis=1)\n",
    "y = df['Customer Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1f373",
   "metadata": {
    "id": "97e1f373"
   },
   "outputs": [],
   "source": [
    "# Then divide data into 4 parts\n",
    "# X_train\n",
    "# X_test\n",
    "# y_train\n",
    "# y_test\n",
    "# test_size=0.2 :     80% train data and 20% is the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9532c2",
   "metadata": {
    "id": "3d9532c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375ef65",
   "metadata": {
    "id": "2375ef65",
    "outputId": "9cf50d43-3d91-49b2-f2f3-7a584f02b69d"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape),\n",
    "print(X_test.shape),\n",
    "print(y_train.shape),\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c6a54",
   "metadata": {
    "id": "d92c6a54"
   },
   "source": [
    "# Remove Outlier from Train Data using Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895ab27",
   "metadata": {
    "id": "b895ab27"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Define the columns for which you want to remove outliers\n",
    "selected_columns = ['Number of Dependents', 'Avg Monthly GB Download', 'Total Refunds',\n",
    "                    'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue']\n",
    "\n",
    "# Calculate the Z-scores for the selected columns in the training data\n",
    "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
    "\n",
    "# Set a threshold value for outlier detection (e.g., 3)\n",
    "threshold = 3\n",
    "\n",
    "# Find the indices of outliers based on the threshold\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "\n",
    "# Remove the outliers from the training data\n",
    "X_train = X_train.drop(X_train.index[outlier_indices])\n",
    "y_train = y_train.drop(y_train.index[outlier_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d16f38",
   "metadata": {
    "id": "25d16f38"
   },
   "source": [
    "# With out hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622ef5c",
   "metadata": {
    "id": "0622ef5c"
   },
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f40ca9",
   "metadata": {
    "id": "78f40ca9"
   },
   "source": [
    "- Model devlopement :  X_train, Y_train\n",
    "\n",
    "- Predictions on :      X_test\n",
    "\n",
    "- Metrics:              Predictions and Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37360711",
   "metadata": {
    "id": "37360711"
   },
   "source": [
    "$Step-1$: **Model development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e187fd",
   "metadata": {
    "id": "33e187fd",
    "outputId": "fc0cdc9a-5ecc-461e-e17f-571e7d4fc4d9"
   },
   "outputs": [],
   "source": [
    "# Decision tree fitting is done\n",
    "# Model is developed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4f75c",
   "metadata": {
    "id": "4eb4f75c"
   },
   "source": [
    "$Step-2$: **Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668064ed",
   "metadata": {
    "id": "668064ed",
    "outputId": "c9e5b099-312e-47bc-a8e1-23d02371fc2e"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741847a4",
   "metadata": {
    "id": "741847a4",
    "outputId": "41bf3188-d93e-4365-ba0a-740695ca989c"
   },
   "outputs": [],
   "source": [
    "# For predictions need to pass X_test\n",
    "y_pred_dt=dtree.predict(X_test)\n",
    "y_pred_dt\n",
    "\n",
    "#Customer Status: ['Stayed' 'Churned']\n",
    "#Customer Status: [1 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085810e",
   "metadata": {
    "id": "7085810e"
   },
   "source": [
    "$Step-3$: **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69312b8a",
   "metadata": {
    "id": "69312b8a",
    "outputId": "05c59e01-92af-467e-9f53-824f0b9807cd"
   },
   "outputs": [],
   "source": [
    "# Metrics calculate by using actual y_test and y_predictions\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "acc_dt= round(accuracy_score(y_test,y_pred_dt)*100,2)\n",
    "f1_dt=round(f1_score(y_test,y_pred_dt),2)\n",
    "precision_dt=round(precision_score(y_test,y_pred_dt),2)\n",
    "recall_dt=round(recall_score(y_test,y_pred_dt),2)\n",
    "print(\"accuray is:\",acc_dt)\n",
    "print(\"F1 is:\",f1_dt)\n",
    "print(\"Precision is:\",precision_dt)\n",
    "print(\"Recall is:\",recall_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd037c8",
   "metadata": {
    "id": "5fd037c8",
    "outputId": "03996ffe-4dc0-4538-8e8c-fe764306f6e6"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_dt))\n",
    "\n",
    "# Out of 967 = 602(1) + 305 (0)\n",
    "# P= TP/TP+FP ===== > 0.83\n",
    "# R= TP/TP+FN ==== > 0.81\n",
    "\n",
    "# pls concentrae only on TPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c0cef",
   "metadata": {
    "id": "004c0cef"
   },
   "source": [
    "**what is Macro avg and what is Weighted avg?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1fe36",
   "metadata": {
    "id": "57e1fe36"
   },
   "source": [
    "**Confusion-matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768192fb",
   "metadata": {
    "id": "768192fb",
    "outputId": "02248cb0-5339-4bee-964a-958bdcb1929d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmt=confusion_matrix(y_test,y_pred_dt)\n",
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aee1f4",
   "metadata": {
    "id": "88aee1f4",
    "outputId": "6635263e-cdd2-4938-b29b-032dc1f52690"
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_dt).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "# Python code and thery concpet the matrix is different\n",
    "# pls keep this in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470f5d9",
   "metadata": {
    "id": "f470f5d9"
   },
   "outputs": [],
   "source": [
    "#2e+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba89599",
   "metadata": {
    "id": "dba89599",
    "outputId": "6a26421b-748e-400b-fcdb-5c3b2e77f578"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cmt,annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f7b38",
   "metadata": {
    "id": "b18f7b38"
   },
   "source": [
    "**ROC-AUC curve**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b7fc9",
   "metadata": {
    "id": "d72b7fc9"
   },
   "source": [
    "- Consider there are two classes are there\n",
    "- for every observations it will give probabilities\n",
    "- Whcih ever is the highest probability that class will be the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ef658",
   "metadata": {
    "id": "a35ef658"
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Roc_curve.svg/220px-Roc_curve.svg.png\" jsaction=\"load:XAeZkd;\" jsname=\"HiaYvf\" class=\"n3VNCb pT0Scc KAlRDb\" alt=\"Receiver operating characteristic - Wikipedia\" data-noaft=\"1\" style=\"width: 220px; height: 220px; margin: 0px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075263b5",
   "metadata": {
    "id": "075263b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "probs=dtree.predict_proba(X_test)\n",
    "\n",
    "# Predict will give all the answers\n",
    "# predict_prob ==== both labels probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86daba",
   "metadata": {
    "id": "1e86daba",
    "outputId": "6241798d-cc59-4b87-b4de-4a6bbc847bcd"
   },
   "outputs": [],
   "source": [
    "probs[2]\n",
    "# what is the max value=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd08656",
   "metadata": {
    "id": "7cd08656",
    "outputId": "982bb53d-6e58-496f-e78a-737ecf8224e5"
   },
   "outputs": [],
   "source": [
    "np.argmax(probs[2])\n",
    "\n",
    "# Third test sample i.e. ID=2\n",
    "# Maximum probability is for class zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88eefbd",
   "metadata": {
    "id": "c88eefbd",
    "outputId": "435a6a0d-f350-497f-e40e-a2235fcf487a"
   },
   "outputs": [],
   "source": [
    "prob_data=pd.DataFrame(probs,columns=['Churned','Stayed'])\n",
    "prob_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc82067",
   "metadata": {
    "id": "2cc82067",
    "outputId": "43a1ac1b-628c-420b-bfac-341b4775ae29"
   },
   "outputs": [],
   "source": [
    "dtree.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Only class-1 probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e53fd",
   "metadata": {
    "id": "806e53fd"
   },
   "source": [
    "- Every metric\n",
    "\n",
    "       y_test(y_actual)  vs    y_predictions\n",
    "\n",
    "- ROC-AUC       \n",
    "\n",
    "       y_test            vs    y_prediction_probabilities (only class-1 probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8c8b0",
   "metadata": {
    "id": "40a8c8b0",
    "outputId": "5d910b8e-65e6-4bf2-f9c7-784c91373ee9"
   },
   "outputs": [],
   "source": [
    "y_dt_pred_prob=dtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_dt_pred_prob)\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e357c9",
   "metadata": {
    "id": "b2e357c9"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfc406",
   "metadata": {
    "id": "65cfc406",
    "outputId": "4cceecf2-837b-4d2c-bfe0-f9a0dacac948"
   },
   "outputs": [],
   "source": [
    "### All together\n",
    "# =======================Step-1:  divide data into input and target=====================================\n",
    "\n",
    "\n",
    "X = df.drop('Customer Status', axis=1)\n",
    "y = df['Customer Status']\n",
    "\n",
    "\n",
    "# ================================Step-2:  divide data into 4 parts  X_train,X_test,Y_train,Y_test======================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "# ========================Step-3: Outlier analysis based on z-score========================================\n",
    "\n",
    "from scipy import stats\n",
    "selected_columns = ['Number of Dependents', 'Avg Monthly GB Download', 'Total Refunds',\n",
    "                    'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue']\n",
    "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
    "threshold = 3\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "X_train = X_train.drop(X_train.index[outlier_indices])\n",
    "y_train = y_train.drop(y_train.index[outlier_indices])\n",
    "\n",
    "# ===============================Step-4:  Train the Model===================================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# =============================Step-5:  Predictions============================================================\n",
    "\n",
    "y_pred_dt=dtree.predict(X_test)\n",
    "\n",
    "# ============================ Step-6: Metrics==================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "acc_dt= round(accuracy_score(y_test,y_pred_dt)*100,2)\n",
    "f1_dt=round(f1_score(y_test,y_pred_dt),2)\n",
    "precision_dt=round(precision_score(y_test,y_pred_dt),2)\n",
    "recall_dt=round(recall_score(y_test,y_pred_dt),2)\n",
    "print(\"accuray is:\",acc_dt)\n",
    "print(\"F1 is:\",f1_dt)\n",
    "print(\"Precision is:\",precision_dt)\n",
    "print(\"Recall is:\",recall_dt)\n",
    "\n",
    "# ================================Step-7:Confusion matrix=========================================================================\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "cmt=confusion_matrix(y_test,y_pred_dt)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cmt,\n",
    "                            display_labels = [False, True])\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_dt).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "#=======================================Step-8: ROC-AUC curve================================================================\n",
    "\n",
    "y_dt_pred_prob=dtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_dt_pred_prob)\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fd4e3",
   "metadata": {
    "id": "4d5fd4e3"
   },
   "outputs": [],
   "source": [
    "y_pred_dt[:5]\n",
    "\n",
    "\n",
    "# Every ML algorithm will provide praobaility first\n",
    "# Output has two labels :  Stayed  Churnder\n",
    "# For evert test case ======== two probabilities\n",
    "# Whcih ever is the highest probability ======= answer\n",
    "# passing first test case ========= [p(churned)=0,p(stayed)=1]====>                          [Output:stayed ====== > 1]\n",
    "\n",
    "# Third test case ================ [P(churned)=1., P(stayed)=0.]====Hihest=p(churned)=1 =====[output:churned ==== 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb45bb7",
   "metadata": {
    "id": "6eb45bb7"
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "**With out Hyper parameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473c768",
   "metadata": {
    "id": "2473c768",
    "outputId": "d83e9979-d2d8-40b1-bfae-61583c8f4964"
   },
   "outputs": [],
   "source": [
    "\n",
    "### All together\n",
    "# ======================= Step-1:  divide data into input and target=====================================\n",
    "\n",
    "\n",
    "X = df.drop('Customer Status', axis=1)\n",
    "y = df['Customer Status']\n",
    "\n",
    "\n",
    "# ================================Step-2:  divide data into 4 parts  X_train,X_test,Y_train,Y_test======================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "# ========================Step-3: Outlier analysis based on z-score========================================\n",
    "\n",
    "from scipy import stats\n",
    "selected_columns = ['Number of Dependents', 'Avg Monthly GB Download', 'Total Refunds',\n",
    "                    'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue']\n",
    "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
    "threshold = 3\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "X_train = X_train.drop(X_train.index[outlier_indices])\n",
    "y_train = y_train.drop(y_train.index[outlier_indices])\n",
    "\n",
    "# ===============================Step-4:  Train the Model===================================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logtree=LogisticRegression()\n",
    "logtree.fit(X_train, y_train)\n",
    "\n",
    "# =============================Step-5:  Predictions============================================================\n",
    "\n",
    "y_pred_log=logtree.predict(X_test)\n",
    "\n",
    "# ============================ Step-6: Metrics==================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "acc_log= round(accuracy_score(y_test,y_pred_log)*100,2)\n",
    "f1_log=round(f1_score(y_test,y_pred_log),2)\n",
    "precision_log=round(precision_score(y_test,y_pred_log),2)\n",
    "recall_log=round(recall_score(y_test,y_pred_log),2)\n",
    "print(\"accuray is:\",acc_log)\n",
    "print(\"F1 is:\",f1_log)\n",
    "print(\"Precision is:\",precision_log)\n",
    "print(\"Recall is:\",recall_log)\n",
    "\n",
    "# ================================Step-7:Confusion matrix=========================================================================\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "cmt=confusion_matrix(y_test,y_pred_log)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cmt,\n",
    "                            display_labels = [False, True])\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_log).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "#=======================================Step-8: ROC-AUC curve================================================================\n",
    "\n",
    "y_log_pred_prob=logtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_log_pred_prob)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ace71",
   "metadata": {
    "id": "d41ace71"
   },
   "source": [
    "### Naive Bayes\n",
    "\n",
    "**With out hyperaparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c7f7b",
   "metadata": {
    "id": "fd2c7f7b",
    "outputId": "a079cfc7-9320-4226-be84-e7d0e25f1892"
   },
   "outputs": [],
   "source": [
    "### All together\n",
    "# ======================= Step-1:  divide data into input and target=====================================\n",
    "\n",
    "\n",
    "X = df.drop('Customer Status', axis=1)\n",
    "y = df['Customer Status']\n",
    "\n",
    "\n",
    "# ================================Step-2:  divide data into 4 parts  X_train,X_test,Y_train,Y_test======================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "# ========================Step-3: Outlier analysis based on z-score========================================\n",
    "\n",
    "from scipy import stats\n",
    "selected_columns = ['Number of Dependents', 'Avg Monthly GB Download', 'Total Refunds',\n",
    "                    'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue']\n",
    "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
    "threshold = 3\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "X_train = X_train.drop(X_train.index[outlier_indices])\n",
    "y_train = y_train.drop(y_train.index[outlier_indices])\n",
    "\n",
    "# ===============================Step-4:  Train the Model===================================================\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NBtree=GaussianNB()\n",
    "NBtree.fit(X_train, y_train)\n",
    "\n",
    "# =============================Step-5:  Predictions============================================================\n",
    "\n",
    "y_pred_NB=NBtree.predict(X_test)\n",
    "\n",
    "# ============================ Step-6: Metrics==================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "acc_NB= round(accuracy_score(y_test,y_pred_NB)*100,2)\n",
    "f1_NB=round(f1_score(y_test,y_pred_NB),2)\n",
    "precision_NB=round(precision_score(y_test,y_pred_NB),2)\n",
    "recall_NB=round(recall_score(y_test,y_pred_NB),2)\n",
    "print(\"accuray is:\",acc_NB)\n",
    "print(\"F1 is:\",f1_NB)\n",
    "print(\"Precision is:\",precision_NB)\n",
    "print(\"Recall is:\",recall_NB)\n",
    "\n",
    "# ================================Step-7:Confusion matrix=========================================================================\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "cmt=confusion_matrix(y_test,y_pred_NB)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cmt,\n",
    "                            display_labels = [False, True])\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_NB).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "#=======================================Step-8: ROC-AUC curve================================================================\n",
    "\n",
    "y_NB_pred_prob=NBtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_NB_pred_prob)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decaddae",
   "metadata": {
    "id": "decaddae"
   },
   "source": [
    "### KNN\n",
    "\n",
    "**With out hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b9a0b",
   "metadata": {
    "id": "669b9a0b",
    "outputId": "3b4482fa-471e-4248-85de-4402121dcd78"
   },
   "outputs": [],
   "source": [
    "### All together\n",
    "# ======================= Step-1:  divide data into input and target=====================================\n",
    "\n",
    "\n",
    "X = df.drop('Customer Status', axis=1)\n",
    "y = df['Customer Status']\n",
    "\n",
    "\n",
    "# ================================Step-2:  divide data into 4 parts  X_train,X_test,Y_train,Y_test======================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "# ========================Step-3: Outlier analysis based on z-score========================================\n",
    "\n",
    "from scipy import stats\n",
    "selected_columns = ['Number of Dependents', 'Avg Monthly GB Download', 'Total Refunds',\n",
    "                    'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue']\n",
    "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
    "threshold = 3\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "X_train = X_train.drop(X_train.index[outlier_indices])\n",
    "y_train = y_train.drop(y_train.index[outlier_indices])\n",
    "\n",
    "# ===============================Step-4:  Train the Model===================================================\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNNtree=KNeighborsClassifier()\n",
    "KNNtree.fit(X_train, y_train)\n",
    "\n",
    "# =============================Step-5:  Predictions============================================================\n",
    "\n",
    "y_pred_KNN=KNNtree.predict(X_test)\n",
    "\n",
    "# ============================ Step-6: Metrics==================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "acc_KNN= round(accuracy_score(y_test,y_pred_KNN)*100,2)\n",
    "f1_KNN=round(f1_score(y_test,y_pred_KNN),2)\n",
    "precision_KNN=round(precision_score(y_test,y_pred_KNN),2)\n",
    "recall_KNN=round(recall_score(y_test,y_pred_KNN),2)\n",
    "print(\"accuray is:\",acc_KNN)\n",
    "print(\"F1 is:\",f1_KNN)\n",
    "print(\"Precision is:\",precision_KNN)\n",
    "print(\"Recall is:\",recall_KNN)\n",
    "\n",
    "# ================================Step-7:Confusion matrix=========================================================================\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "cmt=confusion_matrix(y_test,y_pred_KNN)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cmt,\n",
    "                            display_labels = [False, True])\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_KNN).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "#=======================================Step-8: ROC-AUC curve================================================================\n",
    "\n",
    "y_KNN_pred_prob=KNNtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_KNN_pred_prob)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e73be2",
   "metadata": {
    "id": "43e73be2"
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "**With out hyper pramater tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f302a",
   "metadata": {
    "id": "1e4f302a",
    "outputId": "a03e1aca-8a34-418d-a40d-5b20c07e3150"
   },
   "outputs": [],
   "source": [
    "### All together\n",
    "# ======================= Step-1:  divide data into input and target=====================================\n",
    "\n",
    "\n",
    "X = df.drop('Customer Status', axis=1)\n",
    "y = df['Customer Status']\n",
    "\n",
    "\n",
    "# ================================Step-2:  divide data into 4 parts  X_train,X_test,Y_train,Y_test======================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "# ========================Step-3: Outlier analysis based on z-score========================================\n",
    "\n",
    "from scipy import stats\n",
    "selected_columns = ['Number of Dependents', 'Avg Monthly GB Download', 'Total Refunds',\n",
    "                    'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue']\n",
    "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
    "threshold = 3\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "X_train = X_train.drop(X_train.index[outlier_indices])\n",
    "y_train = y_train.drop(y_train.index[outlier_indices])\n",
    "\n",
    "# ===============================Step-4:  Train the Model===================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFtree=RandomForestClassifier()\n",
    "RFtree.fit(X_train, y_train)\n",
    "\n",
    "# =============================Step-5:  Predictions============================================================\n",
    "\n",
    "y_pred_RF=RFtree.predict(X_test)\n",
    "\n",
    "# ============================ Step-6: Metrics==================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "acc_RF= round(accuracy_score(y_test,y_pred_RF)*100,2)\n",
    "f1_RF=round(f1_score(y_test,y_pred_RF),2)\n",
    "precision_RF=round(precision_score(y_test,y_pred_RF),2)\n",
    "recall_RF=round(recall_score(y_test,y_pred_RF),2)\n",
    "print(\"accuray is:\",acc_RF)\n",
    "print(\"F1 is:\",f1_RF)\n",
    "print(\"Precision is:\",precision_RF)\n",
    "print(\"Recall is:\",recall_RF)\n",
    "\n",
    "# ================================Step-7:Confusion matrix=========================================================================\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "cmt=confusion_matrix(y_test,y_pred_RF)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cmt,\n",
    "                            display_labels = [False, True])\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_RF).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "#=======================================Step-8: ROC-AUC curve================================================================\n",
    "\n",
    "y_RF_pred_prob=RFtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_RF_pred_prob)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d0f42",
   "metadata": {
    "id": "a77d0f42",
    "outputId": "e59259b1-7690-4078-d152-a7011c3c93b7"
   },
   "outputs": [],
   "source": [
    "dict1={'Accuracy':[acc_dt,acc_KNN,acc_log,acc_NB,acc_RF],\n",
    "      \"Precision\":[precision_dt,precision_KNN,precision_log,precision_NB,precision_RF],\n",
    "      \"Recall\":[recall_dt,recall_KNN,recall_log,recall_NB,recall_RF],\n",
    "      \"F1-score\":[f1_dt,f1_KNN,f1_log,f1_NB,f1_RF]}\n",
    "\n",
    "pd.DataFrame(dict1,index=['DT','KNN','Logistic','Naive Bayes','Random Forest'])\n",
    "\n",
    "# Yu can add Confusion matrix details\n",
    "# Based on f1-score model is good\n",
    "# P and R on f1-score\n",
    "# Tp,fp,tn,fn ====== P and R\n",
    "\n",
    "\n",
    "# For binary classification ====== sigmoid (DL)  works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e149ecc",
   "metadata": {
    "id": "1e149ecc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038664bc",
   "metadata": {
    "id": "038664bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dtree = DecisionTreeClassifier(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'random_state': [0, 42]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc285cf",
   "metadata": {
    "id": "0dc285cf"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=42, max_depth=8, min_samples_leaf=3, min_samples_split=2, class_weight='balanced')\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7511a64",
   "metadata": {
    "id": "f7511a64"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = dtree.predict(X_test)\n",
    "print(\"Accuracy Score :\", round(accuracy_score(y_test, y_pred)*100 ,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eff7d7",
   "metadata": {
    "id": "15eff7d7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score, log_loss\n",
    "print('F-1 Score : ',(f1_score(y_test, y_pred, average='micro')))\n",
    "print('Precision Score : ',(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall Score : ',(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Jaccard Score : ',(jaccard_score(y_test, y_pred, average='micro')))\n",
    "print('Log Loss : ',(log_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf8974",
   "metadata": {
    "id": "a3bf8974"
   },
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\n",
    "    \"Feature Name\": X_train.columns,\n",
    "    \"Importance\": dtree.feature_importances_\n",
    "})\n",
    "fi = imp_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "fi2 = fi.head(10)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(data=fi2, x='Importance', y='Feature Name')\n",
    "plt.title('Top 10 Feature Importance Each Attributes (Decision Tree)', fontsize=18)\n",
    "plt.xlabel ('Importance', fontsize=16)\n",
    "plt.ylabel ('Feature Name', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ba0e1",
   "metadata": {
    "id": "ee7ba0e1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(data=cm,linewidths=.5, annot=True,  cmap = 'Blues')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score for Decision Tree: {0}'.format(dtree.score(X_test, y_test))\n",
    "plt.title(all_sample_title, size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37b11f",
   "metadata": {
    "id": "de37b11f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "y_pred_proba = dtree.predict_proba(X_test)[:][:,1]\n",
    "\n",
    "df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test), columns=['y_actual']), pd.DataFrame(y_pred_proba, columns=['y_pred_proba'])], axis=1)\n",
    "df_actual_predicted.index = y_test.index\n",
    "\n",
    "fpr, tpr, tr = roc_curve(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
    "auc = roc_auc_score(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f' %auc)\n",
    "plt.plot(fpr, fpr, linestyle = '--', color='k')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve', size = 15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056203e",
   "metadata": {
    "id": "7056203e"
   },
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9ced8",
   "metadata": {
    "id": "42a9ced8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state': [0, 42]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c8af2",
   "metadata": {
    "id": "3e0c8af2"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=42, max_depth=None, max_features=None, n_estimators=200, class_weight='balanced')\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f3f39",
   "metadata": {
    "id": "0d8f3f39"
   },
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "print(\"Accuracy Score :\", round(accuracy_score(y_test, y_pred)*100 ,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34030228",
   "metadata": {
    "id": "34030228"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score, log_loss\n",
    "print('F-1 Score : ',(f1_score(y_test, y_pred, average='micro')))\n",
    "print('Precision Score : ',(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall Score : ',(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Jaccard Score : ',(jaccard_score(y_test, y_pred, average='micro')))\n",
    "print('Log Loss : ',(log_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64128eb3",
   "metadata": {
    "id": "64128eb3"
   },
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\n",
    "    \"Feature Name\": X_train.columns,\n",
    "    \"Importance\": rfc.feature_importances_\n",
    "})\n",
    "fi = imp_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "fi2 = fi.head(10)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(data=fi2, x='Importance', y='Feature Name')\n",
    "plt.title('Top 10 Feature Importance Each Attributes (Random Forest)', fontsize=18)\n",
    "plt.xlabel ('Importance', fontsize=16)\n",
    "plt.ylabel ('Feature Name', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca95f9",
   "metadata": {
    "id": "1fca95f9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(data=cm,linewidths=.5, annot=True,  cmap = 'Blues')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score for Random Forest: {0}'.format(rfc.score(X_test, y_test))\n",
    "plt.title(all_sample_title, size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38baa4",
   "metadata": {
    "id": "6b38baa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "y_pred_proba = rfc.predict_proba(X_test)[:][:,1]\n",
    "\n",
    "df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test), columns=['y_actual']), pd.DataFrame(y_pred_proba, columns=['y_pred_proba'])], axis=1)\n",
    "df_actual_predicted.index = y_test.index\n",
    "\n",
    "fpr, tpr, tr = roc_curve(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
    "auc = roc_auc_score(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f' %auc)\n",
    "plt.plot(fpr, fpr, linestyle = '--', color='k')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve', size = 15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72a6fd",
   "metadata": {
    "id": "2d72a6fd"
   },
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db6030",
   "metadata": {
    "id": "e5db6030"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6c37d",
   "metadata": {
    "id": "2dc6c37d"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a74a1",
   "metadata": {
    "id": "ee3a74a1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(\"Accuracy Score :\", round(accuracy_score(y_test, y_pred)*100 ,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed10d8f",
   "metadata": {
    "id": "4ed10d8f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score, log_loss\n",
    "print('F-1 Score : ',(f1_score(y_test, y_pred, average='micro')))\n",
    "print('Precision Score : ',(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall Score : ',(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Jaccard Score : ',(jaccard_score(y_test, y_pred, average='micro')))\n",
    "print('Log Loss : ',(log_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88208a",
   "metadata": {
    "id": "cf88208a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(data=cm,linewidths=.5, annot=True,  cmap = 'Blues')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score for XGBoost: {0}'.format(xgb.score(X_test, y_test))\n",
    "plt.title(all_sample_title, size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9aa4a",
   "metadata": {
    "id": "2ac9aa4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "y_pred_proba = xgb.predict_proba(X_test)[:][:,1]\n",
    "\n",
    "df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test), columns=['y_actual']), pd.DataFrame(y_pred_proba, columns=['y_pred_proba'])], axis=1)\n",
    "df_actual_predicted.index = y_test.index\n",
    "\n",
    "fpr, tpr, tr = roc_curve(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
    "auc = roc_auc_score(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f' %auc)\n",
    "plt.plot(fpr, fpr, linestyle = '--', color='k')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve', size = 15)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
